---
name: 'Run QA Test Suite'
description: 'üß™ Core engine for executing API, GUI, and Performance tests with service orchestration and health checks.'
branding:
  icon: 'play-circle'
  color: 'blue'
inputs:
  start-services-command:
    description: '[DEPRECATED] Use setup-services action instead. Command to start background services.'
    required: false
    default: ''
  health-check-urls:
    description: '[DEPRECATED] Use setup-services action instead. Space-separated URLs to wait for.'
    required: false
    default: ''
  test-command-api:
    description: 'Command for API tests (e.g., npm run test:api)'
    required: false
    default: ''
  test-command-performance:
    description: 'Command for Performance tests (e.g., locust -f locustfile.py)'
    required: false
    default: ''
  test-command-gui:
    description: 'Command for GUI tests (e.g., npm run test:gui)'
    required: false
    default: ''
  headless:
    description: 'Run GUI tests in headless mode'
    required: false
    default: 'true'
  enable-coverage:
    description: 'Whether to collect code coverage'
    required: false
    default: 'false'
  coverage-module:
    description: 'Module to collect coverage for'
    required: false
    default: ''
  project-name:
    description: 'Name of the project (e.g., dashboard, ciber). Used for report folder naming.'
    required: false
    default: 'dashboard'
  jira-sync:
    description: 'Enable auto-tagging of scenarios and reporting results to Jira'
    required: false
    default: 'false'
  jira-url:
    description: 'Jira URL (e.g., https://ccgmanjon.atlassian.net)'
    required: false
    default: ''
  jira-user:
    description: 'Jira User Email'
    required: false
    default: ''
  jira-token:
    description: 'Jira API Token'
    required: false
    default: ''
  jira-project-key:
    description: 'Jira Project Key (e.g., DAS)'
    required: false
    default: 'DAS'

runs:
  using: 'composite'
  steps:
    - name: üßπ Pre-execution Cleanup
      shell: bash
      run: |
        echo "::group::Cleanup stale reports"
        rm -rf reports/
        mkdir -p reports/test_run
        mkdir -p reports/performance_run
        echo "Cleanup complete."
        echo "::endgroup::"

    - name: üöÄ Start Services
      if: inputs.start-services-command != ''
      shell: bash
      run: |
        ${{ inputs.start-services-command }}
          
    - name: ‚è≥ Wait for Services
      if: inputs.health-check-urls != ''
      shell: bash
      run: |
        npx wait-on ${{ inputs.health-check-urls }} --timeout 60000 || (cat backend.log 2>/dev/null || true && cat frontend.log 2>/dev/null || true && exit 1)

    - name: üè∑Ô∏è Auto-Tag Gherkin Scenarios with Jira IDs
      if: inputs.jira-sync == 'true'
      shell: bash
      run: |
        echo "::group::Jira Auto-Tagging"
        pip install requests || true
        python ${{ github.action_path }}/scripts/auto_tagger.py
        
        # Commit and Push if changes were made
        git config --global user.name "QA Hub Bot"
        git config --global user.email "bot@qahub.com"
        git add features/**/*.feature
        git diff --quiet && git diff --staged --quiet || (git commit -m "chore(qa): auto-tag new test scenarios [skip ci]" && git push)
        echo "::endgroup::"
      env:
        JIRA_URL: ${{ inputs.jira-url }}
        JIRA_USER: ${{ inputs.jira-user }}
        JIRA_API_TOKEN: ${{ inputs.jira-token }}
        JIRA_PROJECT_KEY: ${{ inputs.jira-project-key }}
        # We assume tests are in features/ directory inside the repo running the action
        FEATURES_DIR: "features"

    - name: üß™ Run API Tests
      if: inputs.test-command-api != ''
      shell: bash
      run: |
        ENABLE_COVERAGE="${{ inputs.enable-coverage }}"
        COVERAGE_MODULE="${{ inputs.coverage-module }}"
        
        if [ "$ENABLE_COVERAGE" = "true" ] && [ -n "$COVERAGE_MODULE" ]; then
          echo "::notice::Running API tests with coverage for module: $COVERAGE_MODULE"
          pytest --cov="$COVERAGE_MODULE" tests/ --cov-report=xml
        else
          echo "::notice::Running standard API tests"
          ${{ inputs.test-command-api }} --project ${{ inputs.project-name }}
        fi

    - name: üß™ Run Performance Tests
      if: inputs.test-command-performance != ''
      shell: bash
      run: |
        echo "::notice::Executing Performance Stability Audit"
        ${{ inputs.test-command-performance }}

    - name: üß™ Run GUI Tests
      if: inputs.test-command-gui != ''
      shell: bash
      run: |
        echo "::notice::Executing GUI Verification Suite"
        ${{ inputs.test-command-gui }} --project ${{ inputs.project-name }}
      env:
        HEADLESS: ${{ inputs.headless }}

    - name: üìä Upload Test Results to Jira
      if: always() && inputs.jira-sync == 'true'
      shell: bash
      run: |
        echo "::group::Jira Test Reporting"
        pip install requests || true
        python ${{ github.action_path }}/scripts/jira_reporter.py
        echo "::endgroup::"
      env:
        JIRA_URL: ${{ inputs.jira-url }}
        JIRA_USER: ${{ inputs.jira-user }}
        JIRA_API_TOKEN: ${{ inputs.jira-token }}
        JIRA_PROJECT_KEY: ${{ inputs.jira-project-key }}
        REPORTS_DIR: "reports/test_run"
